{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookback Length Analysis\n",
    "\n",
    "This notebook analyzes model performance across different lookback lengths and generates visualizations showing how MSE changes as lookback length increases.\n",
    "\n",
    "**Author**: MODE Team\n",
    "\n",
    "**Date**: 2025-12-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Parsing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result_file(filepath):\n",
    "    \"\"\"\n",
    "    Parse a model result file and extract MSE and MAE values.\n",
    "\n",
    "    Format:\n",
    "    (Dataset ModelName)\n",
    "    Dataset_lookback_pred_model...\\nmse:X, mae:Y\n",
    "    ...\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    model_name = Path(filepath).stem\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    current_dataset = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Check for dataset header: (Dataset ModelName)\n",
    "        match = re.match(r'\\((\\w+)\\s+(\\w+)\\)', line)\n",
    "        if match:\n",
    "            dataset = match.group(1)\n",
    "            current_dataset = dataset\n",
    "            if dataset not in results:\n",
    "                results[dataset] = {'model_name': model_name, 'mse': {}, 'mae': {}}\n",
    "            continue\n",
    "\n",
    "        # Parse experiment line to get lookback length\n",
    "        # Format: Dataset_lookback_pred_model...\n",
    "        if current_dataset and '_' in line:\n",
    "            parts = line.split('_')\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    lookback = int(parts[1])  # Extract lookback length\n",
    "                    # Next line should contain metrics\n",
    "                    continue\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        # Parse metrics line\n",
    "        if line.startswith('mse:') and current_dataset:\n",
    "            metrics = {}\n",
    "            for metric in line.split(','):\n",
    "                key, value = metric.strip().split(':')\n",
    "                metrics[key] = float(value)\n",
    "\n",
    "            if lookback not in results[current_dataset]['mse']:\n",
    "                results[current_dataset]['mse'][lookback] = metrics['mse']\n",
    "                results[current_dataset]['mae'][lookback] = metrics['mae']\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results(directory):\n",
    "    \"\"\"Load all model results from the directory.\"\"\"\n",
    "    result_files = glob(os.path.join(directory, '*.txt'))\n",
    "    all_results = {}\n",
    "\n",
    "    for filepath in result_files:\n",
    "        model_results = parse_result_file(filepath)\n",
    "        for dataset, data in model_results.items():\n",
    "            model_name = data['model_name']\n",
    "            if dataset not in all_results:\n",
    "                all_results[dataset] = {}\n",
    "            all_results[dataset][model_name] = {\n",
    "                'mse': data['mse'],\n",
    "                'mae': data['mae']\n",
    "            }\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directory containing this notebook\n",
    "notebook_dir = Path.cwd()\n",
    "\n",
    "print(\"Loading model results...\")\n",
    "all_results = load_all_results(notebook_dir)\n",
    "\n",
    "print(f\"Found results for datasets: {list(all_results.keys())}\")\n",
    "print(f\"Models: {list(all_results.get('ECL', {}).keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(all_results):\n",
    "    \"\"\"Create a summary table for all datasets and models.\"\"\"\n",
    "    summary_data = []\n",
    "\n",
    "    for dataset in ['ECL', 'ETTm1', 'Weather']:\n",
    "        if dataset not in all_results:\n",
    "            continue\n",
    "\n",
    "        for model_name in sorted(all_results[dataset].keys()):\n",
    "            model_data = all_results[dataset][model_name]\n",
    "\n",
    "            for lookback in sorted(model_data['mse'].keys()):\n",
    "                summary_data.append({\n",
    "                    'Dataset': dataset,\n",
    "                    'Model': model_name,\n",
    "                    'Lookback': lookback,\n",
    "                    'MSE': model_data['mse'][lookback],\n",
    "                    'MAE': model_data['mae'][lookback]\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(summary_data)\n",
    "    return df\n",
    "\n",
    "summary_df = create_summary_table(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary table for each dataset\n",
    "for dataset in ['ECL', 'ETTm1', 'Weather']:\n",
    "    if dataset not in all_results:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{dataset} DATASET SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    dataset_df = summary_df[summary_df['Dataset'] == dataset]\n",
    "\n",
    "    # Create pivot tables\n",
    "    pivot_mse = dataset_df.pivot(index='Lookback', columns='Model', values='MSE')\n",
    "    pivot_mae = dataset_df.pivot(index='Lookback', columns='Model', values='MAE')\n",
    "\n",
    "    print(\"\\nMSE Results:\")\n",
    "    display(pivot_mse.round(4))\n",
    "\n",
    "    print(\"\\nMAE Results:\")\n",
    "    display(pivot_mae.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lookback_analysis(all_results, output_dir):\n",
    "    \"\"\"Generate lookback analysis plots for each dataset.\"\"\"\n",
    "    import matplotlib.ticker as ticker\n",
    "    \n",
    "    datasets = ['ECL', 'ETTm1', 'Weather']\n",
    "    lookback_values = [48, 96, 192, 336, 720]\n",
    "    lookback_indices = np.arange(len(lookback_values))\n",
    "\n",
    "    # Color palette with variants for harmony\n",
    "    model_colors = {\n",
    "        'MODE': \"#3E34FF\",            # purple base\n",
    "        'Transformer_M': \"#A571EB\",   # purple variant\n",
    "        'Transformer': '#A571EB',     # purple variant\n",
    "        'S_Mamba': \"#00A6FF\",         # blue base\n",
    "        'Reformer_M': \"#EFBF00\",      # blue variant\n",
    "        'Reformer': '#EFBF00',        # blue variant\n",
    "        'iTransformer': \"#48A21B\",    # green base\n",
    "        'Informer_M': \"#DD6B6B\",      # greenish variant for visibility\n",
    "        'Informer': '#DD6B6B'         # greenish variant for visibility\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Line styles to pair with color variants (Informer/Reformer/Transformer emphasized)\n",
    "    model_styles = {\n",
    "        'MODE': '-',\n",
    "        'Transformer_M': '--',\n",
    "        'Transformer': '-',\n",
    "        'S_Mamba': '-',\n",
    "        'Reformer_M': '--',\n",
    "        'Reformer': '-',\n",
    "        'iTransformer': '-',\n",
    "        'Informer_M': '--',\n",
    "        'Informer': '-'\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(8, 2.6), dpi=600)\n",
    "\n",
    "    legend_items = {}\n",
    "\n",
    "    for idx, dataset in enumerate(datasets):\n",
    "        if dataset not in all_results:\n",
    "            axes[idx].text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
    "                          transform=axes[idx].transAxes, fontsize=5, color='#000000')\n",
    "            axes[idx].set_title(dataset, fontsize=6, color='#000000')\n",
    "            continue\n",
    "\n",
    "        ax = axes[idx]\n",
    "\n",
    "        # Linear scale with evenly spaced ticks\n",
    "        ax.set_yscale('linear')\n",
    "        ax.yaxis.set_major_locator(ticker.MaxNLocator(nbins=5, prune=None))\n",
    "        formatter = ticker.FormatStrFormatter('%.2f')\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        for model_name in sorted(all_results[dataset].keys()):\n",
    "            color = model_colors.get(model_name, '#000000')\n",
    "            style = model_styles.get(model_name, '-')\n",
    "\n",
    "            model_data = all_results[dataset][model_name]\n",
    "            mse_values = [model_data['mse'].get(lb, np.nan) for lb in lookback_values]\n",
    "\n",
    "            if not all(np.isnan(mse_values)):\n",
    "                line, = ax.plot(\n",
    "                    lookback_indices,\n",
    "                    mse_values,\n",
    "                    marker='o',\n",
    "                    linewidth=0.8,\n",
    "                    markersize=2.5,\n",
    "                    color=color,\n",
    "                    linestyle=style,\n",
    "                    label=model_name,\n",
    "                    alpha=0.95\n",
    "                )\n",
    "                if model_name not in legend_items:\n",
    "                    legend_items[model_name] = line\n",
    "\n",
    "        ax.set_title(f'{dataset}', fontsize=7, fontweight='bold', color='#000000')\n",
    "        ax.set_xlabel('Lookback Length', fontsize=6, color='#000000')\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel('MSE', fontsize=6, color='#000000')\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_color('#000000')\n",
    "            spine.set_linewidth(0.6)\n",
    "\n",
    "        # Harmonize tick label sizes/colors for both axes\n",
    "        ax.tick_params(axis='both', which='both', colors='#000000', labelsize=5, width=0.6)\n",
    "\n",
    "        ax.grid(False)\n",
    "        ax.xaxis.grid(True, color='#d0d0d0', linestyle='-', alpha=0.35)\n",
    "\n",
    "        ax.set_xticks(lookback_indices)\n",
    "        ax.set_xticklabels(lookback_values, fontsize=5, color='#000000')\n",
    "\n",
    "    # Custom sort order for legend\n",
    "    priority_models = ['MODE', 'S_Mamba', 'iTransformer']\n",
    "    sorted_models = []\n",
    "\n",
    "    # Add priority models first\n",
    "    for m in priority_models:\n",
    "        if m in legend_items:\n",
    "            sorted_models.append(m)\n",
    "            \n",
    "    # Add remaining models alphabetically\n",
    "    remaining = sorted([m for m in legend_items.keys() if m not in sorted_models])\n",
    "    sorted_models.extend(remaining)\n",
    "\n",
    "    handles = [legend_items[m] for m in sorted_models]\n",
    "\n",
    "    # Force single row for legend\n",
    "    ncol = len(sorted_models)\n",
    "\n",
    "    # Reduce spacing between legend and plots\n",
    "    leg = fig.legend(handles, sorted_models, loc='lower center', bbox_to_anchor=(0.5, 0.02),\n",
    "               ncol=ncol, fontsize=5, frameon=False, columnspacing=1.0, handlelength=2.0)\n",
    "\n",
    "    # Bold 'MODE' in legend\n",
    "    for text in leg.get_texts():\n",
    "        if text.get_text() == 'MODE':\n",
    "            text.set_weight('bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.22, wspace=0.15)\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "fig = plot_lookback_analysis(all_results, notebook_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mode-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
